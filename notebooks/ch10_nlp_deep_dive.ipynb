{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "fastai",
      "language": "python",
      "name": "fastai"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "ch10_nlp_deep_dive.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2jHf0L8jgLl"
      },
      "source": [
        "# Basic Model Setup\n",
        "I am skipping the exploration of tokenization methods etc, as I tried to complete this in org mode but ultimately crashed my session trying to run the model on my laptop. For ease of use, I'm replicating this in a notebook and will run it in colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03XThhUHjh3v"
      },
      "source": [
        "%%capture\n",
        "pip install --upgrade fastai"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia5jOMHIjgLo"
      },
      "source": [
        "from fastai.text.all import *\n",
        "path=untar_data(URLs.IMDB)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zv9nGVcjgL5",
        "outputId": "ff7f6c20-5f03-485d-ff3b-2c79e71f2c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "get_imdb = partial(get_text_files, folders = ['train', 'test', 'unsup'])\n",
        "\n",
        "dls_lm = DataBlock(\n",
        "    blocks=TextBlock.from_folder(path, is_lm=True),\n",
        "    get_items=get_imdb, splitter=RandomSplitter(0.1)\n",
        ").dataloaders(path,path=path,bs=128,seq_len=80)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gIrhKPYjgMG"
      },
      "source": [
        "learn = language_model_learner(dls_lm,\n",
        "                               AWD_LSTM,\n",
        "                               drop_mult=0.3,\n",
        "                               metrics=[accuracy,Perplexity()]).to_fp16()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RZBqWXek7xe",
        "outputId": "d836be5e-0942-4983-ccec-21d193ddb53a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "learn.fit_one_cycle(1, 2e-2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.121666</td>\n",
              "      <td>3.921251</td>\n",
              "      <td>0.299427</td>\n",
              "      <td>50.463512</td>\n",
              "      <td>21:43</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEGJ9Z6kjgMQ"
      },
      "source": [
        "This model takes a very long time to run -- so it is good to save our model state periodically. I wonder how I download that from colab. Will have to see."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJfYtLMajgMR",
        "outputId": "a6381dd7-7a33-40ec-c602-f87762f4c247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "learn.save('1epoch')\n",
        "mpath = Path('/root/.fastai/data/imdb/models/1epoch.pth')\n",
        "shutil.copyfile(mpath, Path('/root/1epoch.pth'))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/root/1epoch.pth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGu_28qsjgMb",
        "outputId": "9fcf48ba-f6d5-4138-bb71-7d3739d40786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        }
      },
      "source": [
        "learn=learn.load('1epoch')\n",
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(10,2e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/10 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='50' class='' max='2627' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      1.90% [50/2627 00:23<20:05 4.0331]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4ZUfoHmjgMj"
      },
      "source": [
        "Once we complete this, we can save the whole model *except for the final layer that converts activations to probabilities of picking each token*. The model without the final layer is called the *encoder*. We can use this as the foundation for, in this example, a sentiment analyzer.\n",
        "\n",
        "# Using our Model to Generate Text\n",
        "\n",
        "Our model is trained to guess the next word of the sentence, so we can use it to write reviews. We just need to give it something to start with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpHCCDtxj_v5"
      },
      "source": [
        "TEXT = \"I hated this movie because\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCE = 2\n",
        "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75)\n",
        "         for _ in range(N_SENTENCES)]\n",
        "\n",
        "print(\"\\n\".join(preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-OBv_nEpLCd"
      },
      "source": [
        "# Creating the Classifier DataLoaders\n",
        "We're going to fine-tune our model for the task of sentiment analysis of imdb reviews. To do so, we need to make a new DataLoaders with a `CategoryBlock` indicating the positivity/negativity of the reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyuTBteEpc6Y"
      },
      "source": [
        "dls_clas = DataBlock(\n",
        "    blocks = (TextBlock.from_folder(path, vocab=dls_lm.vocab), CategoryBlock),\n",
        "    get_y = parent_label,\n",
        "    get_items = partial(get_text_files, folders=['train','test']),\n",
        "    splitter=GrandparentSplitter(valid_name='test')\n",
        ").dataloaders(path,path=path,bs=128,seq_len=72)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hkmDa_1p69l"
      },
      "source": [
        "dls_clas.show_batch(max_n=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU4VRzCQqA3_"
      },
      "source": [
        "Two important observations:\n",
        "- We've removed `is_lm = True`. This tells the model we have \"regular\" labeled data and that we're *not* using the next token(s) as labels.\n",
        "- We've passed the `vacab` created for the language model to the datablock. This is to make sure we're using identical correspondence of tokens to indices. If we failed to do so, the already-trained language model would not make sense to this new model and the fine tuning step would be useless."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c26ACl5EqWCj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}