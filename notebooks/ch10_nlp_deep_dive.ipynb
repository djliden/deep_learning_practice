{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "fastai",
      "language": "python",
      "name": "fastai"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "ch10_nlp_deep_dive.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2jHf0L8jgLl"
      },
      "source": [
        "# Basic Model Setup\n",
        "I am skipping the exploration of tokenization methods etc, as I tried to complete this in org mode but ultimately crashed my session trying to run the model on my laptop. For ease of use, I'm replicating this in a notebook and will run it in colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03XThhUHjh3v"
      },
      "source": [
        "%%capture\n",
        "pip install --upgrade fastai"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia5jOMHIjgLo"
      },
      "source": [
        "from fastai.text.all import *\n",
        "path=untar_data(URLs.IMDB)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zv9nGVcjgL5",
        "outputId": "ff7f6c20-5f03-485d-ff3b-2c79e71f2c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "get_imdb = partial(get_text_files, folders = ['train', 'test', 'unsup'])\n",
        "\n",
        "dls_lm = DataBlock(\n",
        "    blocks=TextBlock.from_folder(path, is_lm=True),\n",
        "    get_items=get_imdb, splitter=RandomSplitter(0.1)\n",
        ").dataloaders(path,path=path,bs=128,seq_len=80)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gIrhKPYjgMG"
      },
      "source": [
        "learn = language_model_learner(dls_lm,\n",
        "                               AWD_LSTM,\n",
        "                               drop_mult=0.3,\n",
        "                               metrics=[accuracy,Perplexity()]).to_fp16()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RZBqWXek7xe",
        "outputId": "d836be5e-0942-4983-ccec-21d193ddb53a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "learn.fit_one_cycle(1, 2e-2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.121666</td>\n",
              "      <td>3.921251</td>\n",
              "      <td>0.299427</td>\n",
              "      <td>50.463512</td>\n",
              "      <td>21:43</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEGJ9Z6kjgMQ"
      },
      "source": [
        "This model takes a very long time to run -- so it is good to save our model state periodically. I wonder how I download that from colab. Will have to see."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJfYtLMajgMR",
        "outputId": "a6381dd7-7a33-40ec-c602-f87762f4c247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "learn.save('1epoch')\n",
        "mpath = Path('/root/.fastai/data/imdb/models/1epoch.pth')\n",
        "shutil.copyfile(mpath, Path('/root/1epoch.pth'))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/root/1epoch.pth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGu_28qsjgMb",
        "outputId": "9fcf48ba-f6d5-4138-bb71-7d3739d40786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "learn=learn.load('1epoch')\n",
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(10,2e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      10.00% [1/10 22:40<3:24:07]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.890222</td>\n",
              "      <td>3.781897</td>\n",
              "      <td>0.316748</td>\n",
              "      <td>43.899223</td>\n",
              "      <td>22:40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='2055' class='' max='2627' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      78.23% [2055/2627 16:57<04:43 3.8160]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4ZUfoHmjgMj"
      },
      "source": [
        "Once we complete this, we can save the whole model *except for the final layer that converts activations to probabilities of picking each token*. The model without the final layer is called the *encoder*. We can use this as the foundation for, in this example, a sentiment analyzer.\n",
        "\n",
        "# Using our Model to Generate Text\n",
        "\n",
        "Our model is trained to guess the next word of the sentence, so we can use it to write reviews. We just need to give it something to start with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpHCCDtxj_v5"
      },
      "source": [
        "TEXT = \"I hated this movie because\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCE = 2\n",
        "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75)\n",
        "         for _ in range(N_SENTENCES)]\n",
        "\n",
        "print(\"\\n\".join(preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-OBv_nEpLCd"
      },
      "source": [
        "# Creating the Classifier DataLoaders\n",
        "We're going to fine-tune our model for the task of sentiment analysis of imdb reviews. To do so, we need to make a new DataLoaders with a `CategoryBlock` indicating the positivity/negativity of the reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyuTBteEpc6Y"
      },
      "source": [
        "dls_clas = DataBlock(\n",
        "    blocks = (TextBlock.from_folder(path, vocab=dls_lm.vocab), CategoryBlock),\n",
        "    get_y = parent_label,\n",
        "    get_items = partial(get_text_files, folders=['train','test']),\n",
        "    splitter=GrandparentSplitter(valid_name='test')\n",
        ").dataloaders(path,path=path,bs=128,seq_len=72)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hkmDa_1p69l"
      },
      "source": [
        "dls_clas.show_batch(max_n=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU4VRzCQqA3_"
      },
      "source": [
        "Two important observations:\n",
        "- We've removed `is_lm = True`. This tells the model we have \"regular\" labeled data and that we're *not* using the next token(s) as labels.\n",
        "- We've passed the `vacab` created for the language model to the datablock. This is to make sure we're using identical correspondence of tokens to indices. If we failed to do so, the already-trained language model would not make sense to this new model and the fine tuning step would be useless."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c26ACl5EqWCj"
      },
      "source": [
        "## Batch Sizes for Language Models\n",
        "PyTorch DataLoaders need to collate the items in a batch into a single tensor. We saw this with the image models as well. In that case, we could resize, crop, zoom, etc., without harming our model. In this case, we might rightly assume that essential information would be lost by so distorting our language input.\n",
        "\n",
        "One technique used for images *is* still applicable here: padding. We want to expand the shortest texts to make them the same size. This is accomplished by appending a special padding token. The size of the largest document in each batch will be the target size.\n",
        "\n",
        "This is all done automatically when using a `TextBlock` with `is_ml` set to `False`.\n",
        "\n",
        "## Defining and Running the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV7XI7Y-zULs"
      },
      "source": [
        "learn = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5,\n",
        "                                metrics=accuracy).to_fp16()\n",
        "\n",
        "# Also need to learn the encoder we trained previously\n",
        "learn = learn.load_encoder('finetuned')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3IvVqmJz2zi"
      },
      "source": [
        "And now we can train the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Trybwf4z2Qo"
      },
      "source": [
        "learn.fit_one_cycle(1,2e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c9g2BXwz7od"
      },
      "source": [
        "learn.freeze_to(-2) # all except last two param groups\n",
        "learn.fit_one_cycle(1, slice(1e-2/(2.6**4), 1e-2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yx7uqOh0LNd"
      },
      "source": [
        "learn.freeze_to(-3) # unfreeze a little more\n",
        "learn.fit_one_cycle(1, slice(5e-3/(2.6**4), 5e-3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9NKQWr-0V00"
      },
      "source": [
        "learn.unfreeze() # unfreeze whole model\n",
        "learn.fit_one_cycle(2, slice(1e-3/(2.6**4), 1e-3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-2mvQ5I0pc6"
      },
      "source": [
        "This model was state-of-the-art only a few years ago."
      ]
    }
  ]
}