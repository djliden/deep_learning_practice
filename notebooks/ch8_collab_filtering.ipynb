{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering\n",
    "Problem setting: there are many products and many users. In collaborative filtering, we look at the products the current user has used or liked, find others who have liked similar products, and recommend products that those other users have used or liked.\n",
    "\n",
    "## Latent Factors\n",
    "The foundational idea is that of \"latent factors.\" We don't really need to know much of anything about the users or about the products except for which users have used/liked which products. But we assume there are some underlying unifying characteristics about these users and/or products. Netflix could recommend a bunch of '70s sci-fi without possessing any concept of '70s sci-fi. But that underlying concept is still what we are getting at.\n",
    "\n",
    "## The Data \n",
    "We will use a subset of the `MovieLens` dataset. The full dataset contains tens of millions of movie rankings (a rating, a movie ID, and a user ID). We will use a subset of 100,000 of these rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.collab import *\n",
    "from fastai.tabular.all import *\n",
    "path = untar_data(URLs.ML_100k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  movie  rating  timestamp\n",
       "0   196    242       3  881250949\n",
       "1   186    302       3  891717742\n",
       "2    22    377       1  878887116\n",
       "3   244     51       2  880606923\n",
       "4   166    346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(path/'u.data', delimiter='\\t', header=None,\n",
    "                     names=['user', 'movie', 'rating', 'timestamp'])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the full dataset, this subset contains some of the most popular (most reviewed) movies, and some of the most prolific reviewers of movies. What we are ultimately interested in is being able to assign predicted ratings to user-movie combinations that do not have ratings.\n",
    "\n",
    "## Learning Latent Factors\n",
    "We can imagine a circumstance where each movie is rated according to a handful of factors, and each user has a certain proclivity for those factors. Maybe we have `['recency', 'high action', 'long movie']`. A movie with values `[-0.9, 0, 0.7]` would be an old, medium-action, long movie. A user's preferences can be expressed in the same way. A user who likes new, high-action, short movies could be represented with the list `[0.8, 0.9, -0.7]`. We could determine how likely the user is to like our old movie by taking the dot product. We end up with -1.21 -- a poor match (quality of match here could range from -3 to 3).\n",
    "\n",
    "In the model of interest in this chapter, though, we want the *model* to learn the latent factors so we don't have to. That involves the following steps:\n",
    "\n",
    "1. Randomly initialize some parameters. These parameters are a set of latent factors for each movie and user. We need to choose how many to use, but we do *not* choose what they mean.\n",
    "2. Calculate predictions. We can take the dot products of the parameters for each movie and user to assign a predicted score to each movie/user combination.\n",
    "3. Calculate the loss. We can use any loss function; for now we'll use MSE for simplicity. With these steps in place, we can optimize our parameters with SGD. \n",
    "\n",
    "My question at this phase is: how do we choose to optimize viewer vs. movie parameters? Is there any meaningful difference?\n",
    "\n",
    "## Preparing the DataLoaders\n",
    "We start by getting movie titles and corresponding IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie              title\n",
       "0      1   Toy Story (1995)\n",
       "1      2   GoldenEye (1995)\n",
       "2      3  Four Rooms (1995)\n",
       "3      4  Get Shorty (1995)\n",
       "4      5     Copycat (1995)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(path/'u.item', delimiter='|', encoding='latin-1',\n",
    "                    usecols=(0,1), names=('movie', 'title'), header=None)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>875747190</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>883888671</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>879138235</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>876503793</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  movie  rating  timestamp         title\n",
       "0   196    242       3  881250949  Kolya (1996)\n",
       "1    63    242       3  875747190  Kolya (1996)\n",
       "2   226    242       5  883888671  Kolya (1996)\n",
       "3   154    242       3  879138235  Kolya (1996)\n",
       "4   306    242       5  876503793  Kolya (1996)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with ratings\n",
    "ratings = ratings.merge(movies, on = \"movie\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>927</td>\n",
       "      <td>Next Karate Kid, The (1994)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>334</td>\n",
       "      <td>Touch (1997)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>Ran (1985)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>158</td>\n",
       "      <td>Clear and Present Danger (1994)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122</td>\n",
       "      <td>Seven (Se7en) (1995)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>308</td>\n",
       "      <td>Jean de Florette (1986)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>551</td>\n",
       "      <td>Beavis and Butt-head Do America (1996)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>866</td>\n",
       "      <td>Good Will Hunting (1997)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>776</td>\n",
       "      <td>Congo (1995)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>387</td>\n",
       "      <td>City of Lost Children, The (1995)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a DataLoaders\n",
    "dls = CollabDataLoaders.from_df(ratings, item_name='title', bs=64)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing this in PyTorch\n",
    "We can't use the pandas crosstab presentation directly. We need tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(dls.classes['user'])\n",
    "n_movies = len(dls.classes['title'])\n",
    "n_factors = 5 # Can adjust this however we want\n",
    "\n",
    "user_factors = torch.randn(n_users, n_factors)\n",
    "movie_factors = torch.randn(n_movies, n_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One challenge is how to look up our user-movie correspondences (i.e. to find the indices). To do this, we replace our indices with one-hot coded vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_3 = one_hot(3, n_users).float()\n",
    "one_hot_3[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0450, -0.7446,  0.4735, -1.1242,  1.5116])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors.t() @ one_hot_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same as if we used `user_factors[3]`. This vector-based approach resembles what is occurring behind the scenes. Behind the scences there is an \"embedding matrix\" that is multiplied to find indices.\n",
    "\n",
    "As discussed above, in this model, we're not specifying what the factors of interest are. We're letting the model figure it out for itself by working through the connections between users and movies. We'll be able to see what sorts of movies are \"grouped\" at the end and to isolate genres, blockbusters, etc.\n",
    "\n",
    "## Collaborative Filtering Model from Scratch\n",
    "(begins with a little review of classes). We will use the PyTorch `module` class to define our own dot product class. I updated the original version from p261 to include the addition of `y_range` from 262, ensuring our predictions fall between 0 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProduct(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, y_range = (0,5.5)):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.movie_factors = Embedding(n_movies, n_factors)\n",
    "        self.y_range=y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:,0])\n",
    "        movies = self.movie_factors(x[:,1])\n",
    "        # We defined y_range as a tuple so *self.y_range unpacks it.\n",
    "        return sigmoid_range((users * movies).sum(dim=1), *self.y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.998103</td>\n",
       "      <td>0.979401</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.880873</td>\n",
       "      <td>0.895210</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.649393</td>\n",
       "      <td>0.859019</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.475372</td>\n",
       "      <td>0.863632</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.356564</td>\n",
       "      <td>0.868133</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DotProduct(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5,5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we now have a working model. What are the next steps? Some missing pieces:\n",
    "- Some viewers are just more positive/negative and some movies are just good/bad. How do we account for this?\n",
    "\n",
    "Answer: we currently just have weights. We also need a bias term. One bias term for each viewer and each movie will allow us to adjust for these considerations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.983874</td>\n",
       "      <td>0.975784</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.873935</td>\n",
       "      <td>0.889328</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.673687</td>\n",
       "      <td>0.862587</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.475285</td>\n",
       "      <td>0.869034</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.361868</td>\n",
       "      <td>0.873625</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DotProductBias(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.user_bias = Embedding(n_users,1)\n",
    "        self.movie_factors = Embedding(n_movies, n_factors)\n",
    "        self.movie_bias = Embedding(n_movies,1)\n",
    "        self.y_range=y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:,0])\n",
    "        movies = self.movie_factors(x[:,1])\n",
    "        res = (users*movies).sum(dim=1, keepdim=True)\n",
    "        res += self.user_bias(x[:,0]) + self.movie_bias(x[:,1])\n",
    "        return sigmoid_range(res, *self.y_range)\n",
    "    \n",
    "model = DotProduct(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5,5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Decay\n",
    "Our model actually got worse by the end. Oops. Next time, we'll get into *weight decay* as a method of solving this. Weight decay is L2 regularization. In L2 regularization (ridge regression?) we add the sum of squared weights to the loss function. This discourages overfitting by encouraging lower weights in general. This can discourage overfitting by preventing the model from assigning very high weights associated with certain training situations (?).\n",
    "\n",
    "We can pass `wd` as an argument to `learn.fit_one_cycle`. Different values can have different results (we can vary the degree of regularization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.950541</td>\n",
       "      <td>0.937493</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.850809</td>\n",
       "      <td>0.870629</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.736671</td>\n",
       "      <td>0.822333</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.598251</td>\n",
       "      <td>0.810643</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.500008</td>\n",
       "      <td>0.810843</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DotProductBias(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5,5e-3,wd=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A definite improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our own embedding module\n",
    "We haven't thought much about what `embedding` actually is/does, so we're going to recreate it without using the class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
